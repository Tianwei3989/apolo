{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68948fb",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737baf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, cv2, copy\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "import matplotlib.cm as mpl_color_map\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# get colormap\n",
    "ncolors = 256\n",
    "color_array = plt.get_cmap('gist_gray')(range(ncolors))\n",
    "\n",
    "# change alpha values\n",
    "color_array[:,-1] = np.linspace(1.0,0.0,ncolors)\n",
    "\n",
    "# create a colormap object\n",
    "map_object = LinearSegmentedColormap.from_list(name='gray_alpha',colors=color_array)\n",
    "\n",
    "# register this new colormap with matplotlib\n",
    "plt.register_cmap(cmap=map_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482674ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(44,160,44),(31,119,180),(255,127,14),(214,39,40),(148,103,189),\n",
    "         (140,86,75),(227,119,194),(127,127,127),(188,189,34),(255,152,150),\n",
    "         (23,190,207),(174,199,232),(255,187,120),(152,223,138),(197,176,213),\n",
    "         (196,156,148),(247,182,210),(199,199,199),(219,219,141),(158,218,229),\n",
    "         (57,59,121),(82,84,163),(107,110,207),(156,158,222),(99,121,57),\n",
    "         (140,162,82),(181,207,107),(206,219,156),(140,109,49),(189,158,57),\n",
    "         (231,186,82),(231,203,148),(132,60,57),(173,73,74),(214,97,107),\n",
    "         (123,65,115),(165,81,148),(206,109,189),(222,158,214),(49,130,189),\n",
    "         (107,174,214),(158,202,225),(198,219,239),(230,85,13),(253,141,60),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816991eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ['amusement', 'awe', 'contentment', 'excitement', 'anger', 'disgust', 'fear', 'sadness']\n",
    "emotion_dict = {\n",
    "    \"amusement\": 0, \"awe\": 1, \"contentment\": 2, \"excitement\": 3,\n",
    "    \"anger\": 4, \"disgust\": 5, \"fear\": 6, \"sadness\": 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeca355",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = './data/artworks/'\n",
    "bbox_root = './data/arts_features_vinvl_bbox_col/'\n",
    "heatmap_root = './data/arts_features_vinvl_heatmap_sum_unified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = './data/test.json'\n",
    "df_test = pd.read_json(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011438ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_file = './data/test_result.json'\n",
    "df_test_pred = pd.read_json(test_result_file)\n",
    "df_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f49726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apolo = pd.read_json('./data/apolo.json')\n",
    "df_apolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boxes = []\n",
    "box_cords = []\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "    file_name = df_test.iloc[i]['painting']# .replace('eugã¨ne','eugene')\n",
    "    img_file = os.path.join(img_root,file_name+'.jpg')\n",
    "    img = Image.open(img_file)\n",
    "    w, h = img.size\n",
    "    \n",
    "    bboxes = np.load(bbox_root+file_name.replace('eugã¨ne','eugene')+'.npy', allow_pickle=True)\n",
    "    \n",
    "    box_cord = []\n",
    "    for x in range(bboxes.shape[0]):\n",
    "        bbox = bboxes[x]\n",
    "        x1 = int(bbox[0] * w)\n",
    "        y1 = int(bbox[1] * h)\n",
    "        x2 = int(bbox[2] * w)\n",
    "        y2 = int(bbox[3] * h)\n",
    "        box_cord.append([x1,y1,x2,y2])\n",
    "    \n",
    "    num_boxes.append(bboxes.shape[0])\n",
    "    box_cords.append(box_cord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['num_boxes'] = num_boxes\n",
    "df_test['box_cords'] = box_cords\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e71a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this index to view more annotations\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VinVL bounding bos prediction\n",
    "file_name = df_test['painting'].iloc[idx]\n",
    "img_file = os.path.join(img_root,file_name+'.jpg')\n",
    "img_bbox = Image.open(img_file)\n",
    "img_bbox1 = ImageDraw.Draw(img_bbox)\n",
    "\n",
    "bboxes = df_all_1.iloc[idx]['box_cords']\n",
    "\n",
    "for x in range(len(bboxes)):\n",
    "    img_bbox1.rectangle(bboxes[x], outline =colors[x+1], width=6)\n",
    "    \n",
    "print(idx, file_name)\n",
    "print(df_all_1['emotion'].iloc[idx])\n",
    "print(df_all_1['tokens'].iloc[idx])\n",
    "\n",
    "display(img_bbox.resize((img_bbox.size[0]//3,img_bbox.size[1]//3),Image.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VinVL + CLIP heatmap\n",
    "img = Image.open(img_file)\n",
    "\n",
    "if 'eugã¨ne' in file_name:\n",
    "    file_name = file_name.replace('eugã¨ne', 'eugene')\n",
    "\n",
    "# get heatmap\n",
    "heatmap_file = df_test['painting'].iloc[idx] + '_' + df_all_1['emotion'].iloc[idx] + '.npy'\n",
    "heatmap = np.load(os.path.join(heatmap_root, heatmap_file), allow_pickle=True)\n",
    "\n",
    "w, h = img.size\n",
    "heat_map_ = cv2.resize(heatmap, (w, h), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# process heatmap\n",
    "color_map = mpl_color_map.get_cmap('jet')\n",
    "no_trans_heatmap = color_map(heat_map_)\n",
    "heatmap_ = copy.copy(no_trans_heatmap)\n",
    "heatmap_[:, :, 3] = 0.5\n",
    "heatmap_ = Image.fromarray((heatmap_*255).astype(np.uint8))\n",
    "no_trans_heatmap = Image.fromarray((no_trans_heatmap*255).astype(np.uint8))\n",
    "\n",
    "heatmap_on_image = Image.new(\"RGBA\", img.size)\n",
    "heatmap_on_image = Image.alpha_composite(heatmap_on_image, img.convert('RGBA'))\n",
    "heatmap_on_image = Image.alpha_composite(heatmap_on_image, heatmap_)\n",
    "\n",
    "display(heatmap_on_image.resize((img_bbox.size[0]//3,img_bbox.size[1]//3),Image.ANTIALIAS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WESD prediction\n",
    "mask_t = df_test_pred[df_test_pred.id == df_test['painting'].iloc[idx] + '_' + df_test['emotion'].iloc[idx]].iloc[0]['prediction_matrix']\n",
    "mask_ = np.asarray(mask_t)[:,6].reshape((7,7))\n",
    "mask = (mask_ - np.min(mask_)) / (np.max(mask_) - np.min(mask_))\n",
    "heat_map_ = cv2.resize(np.asarray(mask), (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "# process heatmap\n",
    "color_map = mpl_color_map.get_cmap('jet')\n",
    "no_trans_heatmap = color_map(heat_map_)\n",
    "heatmap_ = copy.copy(no_trans_heatmap)\n",
    "heatmap_[:, :, 3] = 0.5\n",
    "heatmap_ = Image.fromarray((heatmap_*255).astype(np.uint8))\n",
    "no_trans_heatmap = Image.fromarray((no_trans_heatmap*255).astype(np.uint8))\n",
    "\n",
    "heatmap_on_image = Image.new(\"RGBA\", img.size)\n",
    "heatmap_on_image = Image.alpha_composite(heatmap_on_image, img.convert('RGBA'))\n",
    "heatmap_on_image = Image.alpha_composite(heatmap_on_image, heatmap_)\n",
    "\n",
    "# display(heatmap_on_image)\n",
    "display(heatmap_on_image.resize((img_bbox.size[0]//3,img_bbox.size[1]//3),Image.ANTIALIAS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e1ab6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# APOLO annotation\n",
    "paint = df_apolo.iloc[idx]['painting']\n",
    "emotion = df_apolo.iloc[idx]['emotion']\n",
    "\n",
    "mask = np.load(os.path.join('./data/apolo_pixel_map', paint + '_' + emotion + '.npy'),\n",
    "                   allow_pickle=True)\n",
    "\n",
    "img = Image.open(os.path.join('./data/artworks', paint+'.jpg')\n",
    "\n",
    "print(idx, paint, emotion)\n",
    "print(df_apolo.iloc[idx]['utterances'])\n",
    "\n",
    "w, h = img.size\n",
    "heat_map_ = cv2.resize(mask * 255, (w, h), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# process heatmap\n",
    "color_map = mpl_color_map.get_cmap('YlGn')\n",
    "no_trans_heatmap = color_map(heat_map_)\n",
    "heatmap_ = copy.copy(no_trans_heatmap)\n",
    "heatmap_[:, :, 3] = 0.5\n",
    "heatmap_ = Image.fromarray((heatmap_*255).astype(np.uint8))\n",
    "no_trans_heatmap = Image.fromarray((no_trans_heatmap*255).astype(np.uint8))\n",
    "\n",
    "heatmap_on_image = Image.new(\"RGBA\", img.size)\n",
    "heatmap_on_image = Image.alpha_composite(heatmap_on_image, img.convert('RGBA'))\n",
    "heatmap_on_image = Image.alpha_composite(heatmap_on_image, heatmap_)\n",
    "\n",
    "display(heatmap_on_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a44759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155ffa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff097094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c2d258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a419c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec2909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a057c539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
